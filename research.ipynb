{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "72487093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# CONSTANTS\n",
    "n_trials = 5\n",
    "\n",
    "BIN_WIDTH = 1280\n",
    "BLANK_TRIAL_LENGTH = 1500\n",
    "DRIVEN_TRIAL_LENGTH = 1280\n",
    "TIME_RES = 1000\n",
    "\n",
    "V1 = 1\n",
    "V2 = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0f740b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "data_dir = \"./data/v1-v2_gratings/mat_neural_data/\"\n",
    "data_file_l = glob(data_dir + \"*.mat\")\n",
    "data = loadmat(data_file_l[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38895d0c",
   "metadata": {},
   "source": [
    "# Extracting Spikes in a python equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8d528e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data = data[\"neuralData\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "25d41f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trials: 3200.0\n"
     ]
    }
   ],
   "source": [
    "spike_rasters = neural_data[\"spikeRasters\"].item()\n",
    "n_trials, n_populations = spike_rasters.shape\n",
    "\n",
    "# A single trial consists of driven stimulus and a blank screen\n",
    "n_trials /= 2\n",
    "\n",
    "print(f\"n_trials: {n_trials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "96d95869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yields 6400 items for V1 visual cortex where every even index is a driven signal of shape (n_neurons_in_V1, 1280 milliseconds) and the odd indices are blank input of shape (n_neurons_in_V1, 1500 milliseconds)\n",
    "neural_data[\"spikeRasters\"].item()[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e89f8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = np.zeros(n_populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd4a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "edd9e380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_rasters[0, 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d45c2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for populationIndex in range(n_populations):\n",
    "    n_units[populationIndex] = spike_rasters[0, populationIndex].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "53462c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159.,  25.])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d5dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9a446298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the spike rasters for v1 and v2 visual cortex respectively. \n",
    "spike_rasters_v1 = spike_rasters[:, 0]\n",
    "spike_rasters_v2 = spike_rasters[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62671e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3324 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 159 x 1280 for 159 recordings of 1280 milliseconds of gratings \n",
    "# visually shown in v1 primary visual cortex\n",
    "# V1 recordings were created using a Utah array.\n",
    "spike_rasters_v1[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7cca09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2062 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 159 x 1500 for 159 recordings of 1500 milliseconds of a blank screen shown in the v1 primary visual cortex\n",
    "spike_rasters_v1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fffc0e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 295 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25 x 1280 for 25 recordings of 1280 milliseconds of gratings\n",
    "# visually shown in v2 primary visual cortex\n",
    "# V2 recordings were created using tetrodes.\n",
    "# There is a spatial overlap between the V1 and V2 visual cortex\n",
    "spike_rasters_v2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8a9d9b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 178 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25 x 1500 for 25 recordings of 1500 milliseconds of a blank screen\n",
    "# visually shown in v2 primary visual cortex\n",
    "# V2 recordings were created using tetrodes.\n",
    "# There is a spatial overlap between the V1 and V2 visual cortex\n",
    "spike_rasters_v2[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6de5c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = spike_rasters_v2[:].shape[0] // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c03caa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eb257278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "       \twith 295 stored elements in Compressed Sparse Column format>,\n",
       "       <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "       \twith 178 stored elements in Compressed Sparse Column format>,\n",
       "       <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "       \twith 194 stored elements in Compressed Sparse Column format>, ...,\n",
       "       <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "       \twith 66 stored elements in Compressed Sparse Column format>,\n",
       "       <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "       \twith 35 stored elements in Compressed Sparse Column format>,\n",
       "       <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "       \twith 23 stored elements in Compressed Sparse Column format>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_rasters_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6edc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd5277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59449de2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spike_rasters_v2 \u001b[38;5;241m=\u001b[39m \u001b[43mneural_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspikeRasters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# spike_rasters_v2 = neural_data['spikeRasters'][0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neural_data = data[\"neuralData\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spike_rasters = neural_data[\"spikeRasters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59a8bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = data[\"neuralData\"][\"trialId\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8926e26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "281b14a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"neuralData\"][\"unitCodes\"].item()[0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "052c87cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"neuralData\"][\"unitCodes\"].item().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ba3fb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"neuralData\"][\"unitCodes\"].item()[0, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d75da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First blank trial, V1 and V2\n",
    "driven_v1 = spike_rasters.item()[0, 0] # shape: (159, 1500)\n",
    "driven_v2 = spike_rasters.item()[0, 1] # shape: (25, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5172b0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 1280)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the spike recordings from V1 cortex during teh \n",
    "driven_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47a1d001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1280)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driven_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a4c7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for //: 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspike_rasters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1280\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "spike_rasters.item()[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c57689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = neural_data['stim'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42e0c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials, num_pops = spike_rasters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f836cc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9574d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = spike_rasters[0][0]\n",
    "dense_matrix = sparse_matrix.toarray() if isinstance(sparse_matrix, csr_matrix) else sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c09a82b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<159x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 3324 stored elements in Compressed Sparse Column format>,\n",
       "        <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 295 stored elements in Compressed Sparse Column format>],\n",
       "       [<159x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 2062 stored elements in Compressed Sparse Column format>,\n",
       "        <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 178 stored elements in Compressed Sparse Column format>],\n",
       "       [<159x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 2186 stored elements in Compressed Sparse Column format>,\n",
       "        <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 194 stored elements in Compressed Sparse Column format>],\n",
       "       ...,\n",
       "       [<159x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 978 stored elements in Compressed Sparse Column format>,\n",
       "        <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 66 stored elements in Compressed Sparse Column format>],\n",
       "       [<159x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 2427 stored elements in Compressed Sparse Column format>,\n",
       "        <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 35 stored elements in Compressed Sparse Column format>],\n",
       "       [<159x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 1035 stored elements in Compressed Sparse Column format>,\n",
       "        <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "        \twith 23 stored elements in Compressed Sparse Column format>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6f85489",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the dense matrix as a heatmap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdense_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpike Activity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime (ms)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/pyplot.py:3592\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3572\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3590\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3591\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3592\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3596\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3597\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3598\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3602\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3604\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3608\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3609\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3612\u001b[0m     sci(__ret)\n\u001b[1;32m   3613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1527\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1528\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5945\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5945\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5946\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5948\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/image.py:675\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    674\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/image.py:638\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    636\u001b[0m A \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39msafe_masked_invalid(A, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted to float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    641\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the dense matrix as a heatmap\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(dense_matrix, aspect='auto', cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label=\"Spike Activity\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Neuron Index\")\n",
    "plt.title(\"Neural Spike Activity (Raster Plot)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469735c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[<159x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 3324 stored elements in Compressed Sparse Column format>,\n",
       "                <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 295 stored elements in Compressed Sparse Column format>],\n",
       "               [<159x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 2062 stored elements in Compressed Sparse Column format>,\n",
       "                <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 178 stored elements in Compressed Sparse Column format>],\n",
       "               [<159x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 2186 stored elements in Compressed Sparse Column format>,\n",
       "                <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 194 stored elements in Compressed Sparse Column format>],\n",
       "               ...,\n",
       "               [<159x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 978 stored elements in Compressed Sparse Column format>,\n",
       "                <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 66 stored elements in Compressed Sparse Column format>],\n",
       "               [<159x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 2427 stored elements in Compressed Sparse Column format>,\n",
       "                <25x1280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 35 stored elements in Compressed Sparse Column format>],\n",
       "               [<159x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 1035 stored elements in Compressed Sparse Column format>,\n",
       "                <25x1500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "                \twith 23 stored elements in Compressed Sparse Column format>]],\n",
       "              dtype=object)                                                    ]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"neuralData\"][\"spikeRasters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5e0c0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[array([[ 1,  1],\n",
       "                       [ 2,  1],\n",
       "                       [ 2,  2],\n",
       "                       [ 2,  3],\n",
       "                       [ 3,  1],\n",
       "                       [ 3,  2],\n",
       "                       [ 4,  1],\n",
       "                       [ 4,  2],\n",
       "                       [ 5,  1],\n",
       "                       [ 6,  1],\n",
       "                       [ 7,  1],\n",
       "                       [ 8,  1],\n",
       "                       [ 9,  1],\n",
       "                       [ 9,  2],\n",
       "                       [10,  1],\n",
       "                       [10,  2],\n",
       "                       [11,  1],\n",
       "                       [11,  2],\n",
       "                       [12,  1],\n",
       "                       [12,  3],\n",
       "                       [13,  1],\n",
       "                       [14,  1],\n",
       "                       [14,  2],\n",
       "                       [15,  1],\n",
       "                       [15,  2],\n",
       "                       [16,  1],\n",
       "                       [17,  1],\n",
       "                       [17,  2],\n",
       "                       [17,  3],\n",
       "                       [18,  1],\n",
       "                       [19,  1],\n",
       "                       [19,  2],\n",
       "                       [20,  1],\n",
       "                       [20,  2],\n",
       "                       [20,  3],\n",
       "                       [21,  1],\n",
       "                       [21,  2],\n",
       "                       [22,  1],\n",
       "                       [22,  2],\n",
       "                       [23,  1],\n",
       "                       [24,  1],\n",
       "                       [24,  2],\n",
       "                       [25,  1],\n",
       "                       [25,  2],\n",
       "                       [26,  1],\n",
       "                       [27,  1],\n",
       "                       [28,  1],\n",
       "                       [28,  2],\n",
       "                       [29,  1],\n",
       "                       [29,  2],\n",
       "                       [30,  1],\n",
       "                       [30,  2],\n",
       "                       [31,  1],\n",
       "                       [31,  2],\n",
       "                       [32,  1],\n",
       "                       [33,  1],\n",
       "                       [33,  2],\n",
       "                       [34,  1],\n",
       "                       [35,  1],\n",
       "                       [35,  2],\n",
       "                       [36,  1],\n",
       "                       [36,  2],\n",
       "                       [36,  3],\n",
       "                       [36,  4],\n",
       "                       [37,  1],\n",
       "                       [37,  2],\n",
       "                       [38,  1],\n",
       "                       [39,  1],\n",
       "                       [39,  2],\n",
       "                       [40,  1],\n",
       "                       [41,  1],\n",
       "                       [41,  2],\n",
       "                       [42,  1],\n",
       "                       [42,  2],\n",
       "                       [43,  1],\n",
       "                       [43,  2],\n",
       "                       [44,  1],\n",
       "                       [45,  1],\n",
       "                       [45,  2],\n",
       "                       [46,  1],\n",
       "                       [46,  2],\n",
       "                       [46,  3],\n",
       "                       [47,  1],\n",
       "                       [47,  2],\n",
       "                       [48,  1],\n",
       "                       [48,  2],\n",
       "                       [49,  1],\n",
       "                       [49,  2],\n",
       "                       [50,  1],\n",
       "                       [50,  2],\n",
       "                       [50,  3],\n",
       "                       [52,  1],\n",
       "                       [52,  2],\n",
       "                       [53,  1],\n",
       "                       [54,  1],\n",
       "                       [55,  1],\n",
       "                       [56,  1],\n",
       "                       [56,  2],\n",
       "                       [56,  3],\n",
       "                       [57,  1],\n",
       "                       [57,  2],\n",
       "                       [59,  1],\n",
       "                       [59,  3],\n",
       "                       [60,  1],\n",
       "                       [61,  1],\n",
       "                       [61,  2],\n",
       "                       [62,  1],\n",
       "                       [63,  1],\n",
       "                       [64,  1],\n",
       "                       [64,  2],\n",
       "                       [66,  1],\n",
       "                       [67,  1],\n",
       "                       [67,  2],\n",
       "                       [67,  3],\n",
       "                       [68,  1],\n",
       "                       [69,  1],\n",
       "                       [69,  2],\n",
       "                       [70,  1],\n",
       "                       [71,  1],\n",
       "                       [71,  2],\n",
       "                       [72,  1],\n",
       "                       [73,  1],\n",
       "                       [74,  1],\n",
       "                       [74,  2],\n",
       "                       [75,  1],\n",
       "                       [76,  1],\n",
       "                       [76,  2],\n",
       "                       [77,  1],\n",
       "                       [78,  1],\n",
       "                       [78,  2],\n",
       "                       [79,  1],\n",
       "                       [79,  2],\n",
       "                       [80,  1],\n",
       "                       [81,  1],\n",
       "                       [81,  2],\n",
       "                       [82,  2],\n",
       "                       [83,  1],\n",
       "                       [84,  1],\n",
       "                       [84,  2],\n",
       "                       [85,  1],\n",
       "                       [85,  2],\n",
       "                       [85,  3],\n",
       "                       [86,  1],\n",
       "                       [87,  1],\n",
       "                       [87,  2],\n",
       "                       [88,  1],\n",
       "                       [88,  2],\n",
       "                       [89,  1],\n",
       "                       [89,  2],\n",
       "                       [90,  1],\n",
       "                       [91,  1],\n",
       "                       [91,  2],\n",
       "                       [92,  1],\n",
       "                       [93,  1],\n",
       "                       [93,  2],\n",
       "                       [94,  1],\n",
       "                       [95,  1],\n",
       "                       [95,  2],\n",
       "                       [96,  1]], dtype=uint16), array([[ 1,  1],\n",
       "                                                        [ 1,  2],\n",
       "                                                        [ 1,  3],\n",
       "                                                        [ 1,  5],\n",
       "                                                        [ 1,  6],\n",
       "                                                        [ 5,  2],\n",
       "                                                        [ 5,  3],\n",
       "                                                        [ 5,  4],\n",
       "                                                        [ 5,  5],\n",
       "                                                        [ 5,  8],\n",
       "                                                        [ 9,  1],\n",
       "                                                        [ 9,  2],\n",
       "                                                        [13,  2],\n",
       "                                                        [13,  3],\n",
       "                                                        [13,  4],\n",
       "                                                        [13,  6],\n",
       "                                                        [13,  8],\n",
       "                                                        [13,  9],\n",
       "                                                        [13, 10],\n",
       "                                                        [17,  1],\n",
       "                                                        [21,  1],\n",
       "                                                        [21,  3],\n",
       "                                                        [21,  4],\n",
       "                                                        [21,  6],\n",
       "                                                        [21,  7]], dtype=uint16)]],\n",
       "              dtype=object)                                                        ]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"neuralData\"][\"unitCodes\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
